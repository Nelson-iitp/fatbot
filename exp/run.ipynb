{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Imports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fatbot as fb\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [define environment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def envF(test):\n",
    "    from fatbot.db import World_Test as World #<-------------- fatbolt.World class\n",
    "    return World( # create and return an instance of World\n",
    "        \n",
    "        #<-------------- fatbot.Swarm instance (refer fatbot.db.GLOBAL_ISD)\n",
    "        swarm=fb.db.swarm_4x(False, '4x2', '4x1'),    \n",
    "\n",
    "        #<-------------- world dynamics \n",
    "        horizon=500,                    #<------ set 0 for infinite horizon\n",
    "        enable_imaging=True,            #<------ enables sensor-ray imaging, disbale if not required\n",
    "        seed=None,                      #<------ prng seed\n",
    "        custom_XY=None,                 #<------ custom XY-range for world (by default copies from swarm, change if needed)\n",
    "\n",
    "\n",
    "        #<-------------- render args \n",
    "        record_reward_hist=test,        #<------ if True, records reward history per episode (and renders it as well)\n",
    "        render_normalized_reward=False, #<------ if True, renders normalized bar plot for reward signal\n",
    "        render_xray_cmap='hot',         #<------ colormap arg for plt.imshow(xray) \n",
    "        render_dray_cmap='copper',      #<------ colormap arg for plt.imshow(dray)\n",
    "        render_dpi=32,                  #<------ dpi arg for plt.figure()\n",
    "        render_figure_ratio=0.4,        #<------ figsize multiplier for arg for plt.figure()\n",
    "        render_bounding_width=0.05,     #<------ how much margin to leave b/w world boundary and figure boundary (%)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [define agent class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inherit from fatbot.Agent\n",
    "class testAgent(fb.Agent):\n",
    "\n",
    "    def __init__(self, base_dir) -> None:\n",
    "        model_type='ppo'                #<---- (str) - check fatbot.agents.MODEL_TYPES for available model types\n",
    "        super().__init__(\n",
    "            model_type=model_type,\n",
    "            model_name = f'{str(__class__.__name__)}_{model_type}',\n",
    "            base_dir=base_dir,\n",
    "            training_env= envF(False),\n",
    "            testing_env= envF(True)) \n",
    "\n",
    "    def __call__(self): #<--- trains on call, learn_args and model_args are provided to model_type.learn() \n",
    "        self.train( #<--- will set self.model to a trained sb3 model\n",
    "\n",
    "            learn_args = dict(total_timesteps = 10_000, log_interval = 100_000),\n",
    "\n",
    "            model_args = dict(# env = ? #<----- do not provide env here\n",
    "                            policy =                    'MlpPolicy',\n",
    "                            learning_rate=              0.0003, # schedule\n",
    "                            n_steps=                    2048, \n",
    "                            batch_size=                 64, \n",
    "                            n_epochs=                   10, \n",
    "                            gamma=                      0.99, \n",
    "                            gae_lambda=                 0.95, \n",
    "                            clip_range=                 0.2, # schedule\n",
    "                            clip_range_vf=              None, # schedule\n",
    "                            normalize_advantage=        True, \n",
    "                            ent_coef=                   0.0, \n",
    "                            vf_coef=                    0.5, \n",
    "                            max_grad_norm=              0.5, \n",
    "                            target_kl=                  None,\n",
    "                            verbose=                    0, \n",
    "                            seed=                       None, \n",
    "                            device=                     'cpu', \n",
    "                            policy_kwargs=              dict(\n",
    "                                                            activation_fn=nn.LeakyReLU,\n",
    "                                                            net_arch=[dict(\n",
    "                                                                pi=[256, 256, 256, 256], \n",
    "                                                                vf=[256, 256, 256, 256])])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [create agent instance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = testAgent(base_dir='./test_dir') #<----- select base directory (for current run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent() #<---- trains on call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_return, total_steps = \\\n",
    "agent.test(\n",
    "    episodes=2,                     #<----- total no of episodes\n",
    "    steps=50,                      #<----- steps per episodes (0 for inifite horizon - i.e. untill env.is_done() returns true)\n",
    "    deterministic=False,             #<----- arg for model.predict()\n",
    "    render_mode='all',              #<----- render_mode = all, env, sen, rew  (keep blank for no rendering)\n",
    "    save_fig='run',                 #<----- (figure directory) for saving plt.figures or (video name) if make_video is true\n",
    "    save_dpi='figure',              #<----- dpi for plt.savefig(), NOTE: 'figure' means use fig's dpi (as define in env.render_dpi)\n",
    "    make_video=True,                #<----- if True, compiles a video of all rendered frames\n",
    "    video_fps=2,                    #<----- frames per second for video (default=1)\n",
    "    starting_state=None,            #<----- (None :: selects randomly) or (lambda epsisode: state_index :: selects index on given episodes) \n",
    ")\n",
    "print(f'{average_return=}, {total_steps=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('done!')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
